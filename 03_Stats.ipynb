{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MMRES-PyBootcamp/MMRES-python-bootcamp2024/blob/master/03_Stats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqAIqBlSmD4w"
   },
   "source": [
    "# Session 3 - Statistics in Python (First part - 30')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A very (very) basic introduction on statistics in Python. In this first introductory lesson we will just present some *Measures of Central Tendency* (median, mean and weighted mean) and *Measures of Variability* (variance and standard deviation). We will also talk about *Percentiles* and *Missing values*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    " * [Measures of Central Tendency](#Measures-of-Central-Tendency)\n",
    "   * [Median](#Median)\n",
    "   * [Mean](#Mean)\n",
    "   * [Weighted mean](#Weighted-mean) \n",
    " * [Measures of Variability](#Measures-of-Variability)\n",
    "   * [Variance](#Variance)\n",
    "   * [Standard deviation](#Standard-deviation)\n",
    " * [Percentiles](#Percentiles)\n",
    "   * [Outliers (and whiskers)](#Outliers-(and-whiskers))\n",
    " * [Missing values](#Missing-values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document is devised as a tool to enable your **self-learning process**. If you get stuck at some step or need any kind of help, please don't hesitate to raise your hand and ask for the teacher's guidance. Along it, you will find some **special cells**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Practice:</b> Practice cells announce exercises that you should try during the current boot camp session. Usually, solutions are provided using hidden cells (look for the dot dot dot symbol \"...\" and click to unravel them and check that your try is correct).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Extension:</b> Extension cells correspond to exercises (or links to contents) that are a bit more advanced. We recommend to try them after the current boot camp session.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Tip:</b> Tip cells just give some advice or complementary information.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"><b>Caveat:</b> Caveat cells warn you about the most common pitfalls one founds when starts his/her path learning Python.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this basic introduction on statistics in Python we will leverage some NumPy functions. Let's import this package with its typical alias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "86WqXweTk9Jh"
   },
   "outputs": [],
   "source": [
    "# Load package with its corresponding alias\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Tip:</b> You will devote a whole boot camp session to NumPy on October 1<sup>st</sup> (12:30-14:00) with Lidia Mateo.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTTVyKXslupX"
   },
   "source": [
    "# Measures of Central Tendency\n",
    "\n",
    "The measures of central tendency show the central or middle values of data sets. There are several definitions of what's considered to be the center of a data set. In this tutorial, you'll learn how to identify and calculate these measures of central tendency. Let's create a list with some arbitrary values to work with along the upcoming sections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list with some floats and integers\n",
    "x = [8.0, 1, 2.5, 4, 28.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svQtQ0aEmgWU",
    "tags": []
   },
   "source": [
    "## Median\n",
    "\n",
    "The sample median is the middle element of a sorted data set. We can compute the median using the NumPy function [`np.median()`](https://numpy.org/doc/stable/reference/generated/numpy.median.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FU89gVremmSl",
    "outputId": "f6897dad-1771-4160-f6d4-5c354d84a597"
   },
   "outputs": [],
   "source": [
    "# Compute the median of \"x\"\n",
    "x_median = np.median(x)\n",
    "\n",
    "# Return \"x_median\"\n",
    "print(x_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the middle element of the sorted `x` list is precisely `4`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the list with some floats and integers we defined above\n",
    "sorted(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean\n",
    "\n",
    "The sample mean (also called the sample arithmetic mean or simply the average) of a collection of values, $\\bar{x}$, is defined as follows:\n",
    "\n",
    "$$\\bar{x} = \\frac{1}{N}\\sum^{N}_{i=1}{x_i}$$\n",
    "\n",
    "where $x_i$ is the i<sup>th</sup> element of the collection and $N$ the number of elements comprising such collection. You have already seen that you can calculate the mean using the Python built-ins `sum()` and `len()`, without importing packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1LnbFPQplR--",
    "outputId": "ed07a231-1a32-4a40-a13c-1b8d5f1e1329"
   },
   "outputs": [],
   "source": [
    "# Compute and store the mean of \"x\" in \"x_mean_builtin\"\n",
    "x_mean_builtin = sum(x) / len(x)\n",
    "\n",
    "# Return \"x_mean_builtin\"\n",
    "print(x_mean_builtin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can alternatively use the NumPy function [`np.mean()`](https://numpy.org/doc/stable/reference/generated/numpy.mean.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8DDg71BHlZ_I",
    "outputId": "64f2949b-678f-4863-d179-41c56bc20df4"
   },
   "outputs": [],
   "source": [
    "# Compute and store the mean of \"x\" in \"x_mean\"\n",
    "x_mean = np.mean(x)\n",
    "\n",
    "# Return \"x_mean\"\n",
    "print(x_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NS88kTWll_Qw"
   },
   "source": [
    "## Weighted mean\n",
    "\n",
    "The weighted mean (also called the weighted arithmetic mean or weighted average) of a collection of values, $\\bar{x}_{w}$, is a generalization of the mean that enables you to define the relative contribution of each value to the result:\n",
    "\n",
    "$$\\bar{x}_{w} = \\frac{\\sum^{N}_{i=1}{x_i w_i}}{\\sum^{N}_{i=1}{w_i}}$$\n",
    "\n",
    "where $x_i$ is the i<sup>th</sup> element of the collection, $w_i$ its weight, and $N$ the number of elements comprising such collection. The weighted mean is very handy when you need the mean of a data set containing items that occur with given relative frequencies. For example, remember the values stored in our list `x`, say that you have a collection of values in which 60 % of all items are equal to `8.0`, 20 % are equal to `1`, 10 % are equal to `2.5`, 8 % are equal to `4` and 2 % are equal to `28.0`. You can calculate the mean of such a collection using the NumPy function [`np.average()`](https://numpy.org/doc/stable/reference/generated/numpy.average.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZqCpAWpls1t",
    "outputId": "b1fb159a-6e0f-42c7-dc6d-16c20c880215"
   },
   "outputs": [],
   "source": [
    "# Create a list of weights for the values stored in \"x\"\n",
    "w = [0.60, 0.20, 0.10, 0.08, 0.02]\n",
    "\n",
    "# Compute and store the weighted mean in \"x_weighted_mean\" and the regular mean in \"x_mean\"\n",
    "x_weighted_mean = np.average(x, weights=w)\n",
    "x_mean = np.average(x)\n",
    "\n",
    "# Return \"x_weighted_mean\" and \"x_mean\"\n",
    "print(x_weighted_mean)\n",
    "print(x_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the \"regular\" mean is a particular case of weighted mean on which all weights are identical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDzxAsrumtqT"
   },
   "source": [
    "# Measures of Variability\n",
    "\n",
    "The measures of central tendency aren't sufficient to describe data. You'll also need the measures of variability that quantify the spread of data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance\n",
    "\n",
    "The variance of a collection of values, $\\sigma^2$, is defined as follows:\n",
    "\n",
    "$$\\sigma^2 = \\frac{1}{N-1}\\sum^{N}_{i=1}{\\left(x_i - \\bar{x}\\right)^2}$$\n",
    "\n",
    "where $x_i$ is the i<sup>th</sup> element of the collection, and $N$ and  $\\bar{x}$ are the number of elements and the mean of such collection, respectively. The variance quantifies the spread of the data. It shows numerically how far the values are from the mean. As usual, NumPy has a function for this purpose called [`np.var()`](https://numpy.org/doc/stable/reference/generated/numpy.var.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hNv4Ej79mp24",
    "outputId": "0a607e86-9e58-4064-8089-1b82820322dd"
   },
   "outputs": [],
   "source": [
    "# Compute and store the (biased) sample variance of \"x\" in \"x_var_bias\"\n",
    "x_var_bias = np.var(x, ddof=0)\n",
    "\n",
    "# Compute and store the (unbiased) sample variance of \"x\" in \"x_var_unbias\"\n",
    "x_var_unbias = np.var(x, ddof=1)\n",
    "\n",
    "# Return \"x_var_bias\" and \"x_var_unbias\"\n",
    "print(x_var_bias)\n",
    "print(x_var_unbias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, [`np.var()`](https://numpy.org/doc/stable/reference/generated/numpy.var.html) uses `ddof=0` (Delta Degrees of Freedom), which gives the *biased sample variance*. By changing `ddof=1` you get the *unbiased sample variance* (AKA [Bessel's correction](https://en.wikipedia.org/wiki/Bessel%27s_correction)). From now on, we will use the *unbiased sample variance*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wb7KAv_zm2_C"
   },
   "source": [
    "## Standard deviation\n",
    "\n",
    "The standard deviation, $\\sigma$, is defined as follows:\n",
    "\n",
    "$$\\sigma = \\sqrt{\\frac{1}{N-1}\\sum^{N}_{i=1}{\\left(x_i - \\bar{x}\\right)^2}}$$\n",
    "\n",
    "where $x_i$ is the i<sup>th</sup> element of the collection, and $N$ and  $\\bar{x}$ are the number of elements and the mean of such collection, respectively. The standard deviation is another measure of data spread which is often more convenient than the variance because it has the same dimensionality (units) as its associated values. You can compute the standard deviation just by taking the square root of the variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S47vO1HnJfET"
   },
   "outputs": [],
   "source": [
    "# Compute and store the variance of \"x\" in \"x_var\"\n",
    "x_var = np.var(x, ddof=1)\n",
    "\n",
    "# Compute and store the standard deviation of \"x\" in \"x_std\"\n",
    "x_std = np.sqrt(x_var)\n",
    "\n",
    "# Return \"x_std\"\n",
    "print(x_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can use the NumPy function [`np.std()`](https://numpy.org/doc/stable/reference/generated/numpy.std.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and store the standard deviation of \"x\" in \"x_std\"\n",
    "x_std = np.std(x, ddof=1)\n",
    "\n",
    "# Return \"x_std\"\n",
    "print(x_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbCvXLHEJsnn"
   },
   "source": [
    "# Percentiles\n",
    "\n",
    "Percentiles are used to express where a value falls in a range of other values. It's like a competition in which we *increasingly sort* them (the smallest value is the first and the largest value is the last): Therefore, the 0<sup>th</sup> percentile is the first value of the collection (the smallest), the 100<sup>th</sup> percentile is last value of the collection (the largest), the 25<sup>th</sup> percentile (a.k.a. the first quartile) is the value having 25 % of the values of the collection in front and 75 % behind, and so on. The NumPy function to get your percentiles is [`np.percentile()`](https://numpy.org/doc/stable/reference/generated/numpy.percentile.html). For example, let's say we have an array of the ages of all the people that lives in a village:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "43YBIOfQJoJF",
    "outputId": "6d23470f-c8e0-40c8-c3e7-982ad36a8960"
   },
   "outputs": [],
   "source": [
    "# Create list with some ages\n",
    "ages = [50, 61, 43, 48, 50, 41, 72, 55, 15, 39, 80, 82, 72, 1, 81, 69, 65, 54, 50, 61, 31, 115]\n",
    "\n",
    "# Compute the percentile 75 of \"ages\"\n",
    "ages_75 = np.percentile(ages, 75)\n",
    "\n",
    "# Return \"ages_75\"\n",
    "print(ages_75)\n",
    "\n",
    "# Return \"ages\" sorted\n",
    "print(sorted(ages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 50<sup>th</sup> percentile is just the median:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the percentile 50 equals the median\n",
    "np.percentile(ages, 50) == np.median(ages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, box plots represent three percentiles: 25 (box bottom edge), 50 (mid box) and 75 (box top edge). Let's check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load plotting package seaborn with its corresponding alias\n",
    "import seaborn as sns\n",
    "\n",
    "# Compute the three typical percentiles of \"ages\"\n",
    "print(np.percentile(ages, [25, 50, 75]))\n",
    "\n",
    "# Get box plot for \"ages\"\n",
    "ax = sns.boxplot(x=ages)\n",
    "\n",
    "# Mark the three typical percentiles of \"ages\"\n",
    "ax.axvline(x=np.percentile(ages, 25), color='red', linestyle='--')\n",
    "ax.axvline(x=np.percentile(ages, 50), color='green', linestyle='--')\n",
    "ax.axvline(x=np.percentile(ages, 75), color='blue', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Tip:</b>. Don't worry abount the Seaborn syntax we are using. We will devote a whole boot camp session to Seaborn on September 19<sup>th</sup> (11:00-12:00).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers (and whiskers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you noticed the two circles appearing in the box plot? These are *outliers*, or values that lay abnormally far away from the other. There is not a universal criterion to define what an *outliers* is. The Seaborn function `boxplot()` for example, uses a definition based on an (arbitrary) 1.5 factor of the *interquartile range* (IQC). The IQC is just the difference between the third quartile (75<sup>th</sup> percentile) and the first quartile (25<sup>th</sup> percentile). Therefore, any value *below* 1.5 x IQC units the 25<sup>th</sup> percentile (first quartile) or *above* 1.5 x IQC units the 75<sup>th</sup> percentile (third quartile) will we highlighted as an outlier. Let's highlight these boundaries in the box plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the third and the first quartiles\n",
    "ages_75 = np.percentile(ages, 75)\n",
    "ages_25 = np.percentile(ages, 25)\n",
    "\n",
    "# Compute the interquartile range\n",
    "ages_iqr = ages_75 - ages_25\n",
    "\n",
    "# Get box plot for \"ages\"\n",
    "ax = sns.boxplot(x=ages)\n",
    "\n",
    "# Mark outliers boundaries\n",
    "ax.axvline(x=ages_25 - (ages_iqr * 1.5), color='magenta', linestyle=':')\n",
    "ax.axvline(x=ages_75 + (ages_iqr * 1.5), color='magenta', linestyle=':')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, there is not a universal criterion on which the whiskers should represent. The Seaborn function `boxplot()` draws the whiskers precisely at the extreme values after discarding the outliers. Let's do this final check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a list comprehension to drop outliers from \"ages\"\n",
    "ages_no_outliers = [age for age in ages if ( age > ages_25 - (ages_iqr * 1.5) ) and ( age < ages_75 + (ages_iqr * 1.5) )]\n",
    "\n",
    "# Get box plot for \"ages\"\n",
    "ax = sns.boxplot(x=ages)\n",
    "\n",
    "# Mark the whiskers\n",
    "ax.axvline(x=min(ages_no_outliers), color='cyan', linestyle='--')\n",
    "ax.axvline(x=max(ages_no_outliers), color='yellow', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values\n",
    "\n",
    "In many scientific disciplines it is very common to deal with \"data holes\" (or *missing values*). In Python, missing values are represented as `nan`, which stands for \"Not a Number\". The NumPy package offers a very efficient implementation `nan` values for Python. Note that Python treats `nan`s as floats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the variable type of a nan\n",
    "type(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the outcome of involving a nan in an arithmetic operation\n",
    "print(np.nan + 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, you should proceed with caution when computing descriptive statistics of data sets containing missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Practice 1:</b>\n",
    "\n",
    "1) In the 1<sup>st</sup> code cell below, check if the mean and the median of `[1, 2, 3, 4, 5, 6]` are equal to the mean and the median of `[np.nan, 1, 2, 3, 4, 5, 6]`, respectively:\n",
    "    \n",
    "2) In the 2<sup>nd</sup> code cell below, do the same as before with the functions [`np.nanmean()`](https://numpy.org/doc/stable/reference/generated/numpy.nanmean.html) instead of [`np.mean()`](https://numpy.org/doc/stable/reference/generated/numpy.mean.html) and [`np.nanmedian()`](https://numpy.org/doc/stable/reference/generated/numpy.nanmedian.html) instead of [`np.median()`](https://numpy.org/doc/stable/reference/generated/numpy.median.html)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean and the median of a dice\n",
    "\n",
    "\n",
    "\n",
    "# Compute the mean and the median of a dice containing a nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the mean and the median of a dice\n",
    "print(np.mean([1, 2, 3, 4, 5, 6]))\n",
    "print(np.median([1, 2, 3, 4, 5, 6]))\n",
    "\n",
    "# Compute the mean and the median of a dice containing a nan\n",
    "print(np.mean([np.nan, 1, 2, 3, 4, 5, 6]))\n",
    "print(np.median([np.nan, 1, 2, 3, 4, 5, 6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the nanmean and the nanmedian of a dice\n",
    "\n",
    "\n",
    "\n",
    "# Compute the nanmean and the nanmedian of a dice containing a nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute the nanmean and the nanmedian of a dice\n",
    "print(np.nanmean([1, 2, 3, 4, 5, 6]))\n",
    "print(np.nanmedian([1, 2, 3, 4, 5, 6]))\n",
    "\n",
    "# Compute the nanmean and the nanmedian of a dice containing a nan\n",
    "print(np.nanmean([np.nan, 1, 2, 3, 4, 5, 6]))\n",
    "print(np.nanmedian([np.nan, 1, 2, 3, 4, 5, 6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `nan` values are not automatically dropped when doing arithmetic computations with NumPy. Some functions (like of `np.mean()` and `np.median()`) try to keep `nan` values, only being able to return a `nan` at the end of the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>Practice 1 ends here.</b>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"><b>Caveat:</b>\n",
    "\n",
    "Dealing with missing values is tricky and usually needs *data imputation* because advanced statistical analyses (like differential gene expression/protein abundance analysis or machine learning) require complete data (with no missing values). Not all data sets can be imputed in the same way so there is no a \"best imputation algorithm\".\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Tip:</b> You will devote a boot camp session to missing values on October 1<sup>st</sup> (12:30-14:00) with Lidia Mateo.</div>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNzEHUEKWP4G0lHcKMGoPob",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "07_scipy_stats.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
